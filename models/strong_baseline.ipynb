{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-05T05:51:22.631951400Z",
     "start_time": "2023-12-05T05:51:22.322238800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "val_df = pd.read_csv(\"../data/validation.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T05:52:15.234647900Z",
     "start_time": "2023-12-05T05:52:06.056884200Z"
    }
   },
   "id": "6b1e3bae8f68614d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train # samples: 287113\n",
      "validation # samples: 13368\n",
      "test # samples: 11490\n"
     ]
    }
   ],
   "source": [
    "print(\"train # samples:\", train_df.shape[0])\n",
    "print(\"validation # samples:\", val_df.shape[0])\n",
    "print(\"test # samples:\", test_df.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T05:53:31.406422800Z",
     "start_time": "2023-12-05T05:53:31.403033400Z"
    }
   },
   "id": "28dd4f6246b4d0d0"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "id                     0001d1afc246a7964130f43ae940af6bc6c57f01\narticle       By . Associated Press . PUBLISHED: . 14:11 EST...\nhighlights    Bishop John Folda, of North Dakota, is taking ...\nName: 0, dtype: object"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T05:57:02.594964800Z",
     "start_time": "2023-12-05T05:57:02.574943500Z"
    }
   },
   "id": "2e481e580266b34e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34cc42648669feb5"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cresc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "import string"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T06:04:58.867222900Z",
     "start_time": "2023-12-05T06:04:57.822251100Z"
    }
   },
   "id": "f477d35e9781c078"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "SYMBOLS = string.punctuation\n",
    "STOPS = set(stopwords.words(\"english\"))\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "def preprocess(news, use_stemmer=False, remove_stopwords=True):\n",
    "    # convert to lower case\n",
    "    news = news.lower()\n",
    "    \n",
    "    # remove punctuations\n",
    "    # news = news.translate(str.maketrans('', '', SYMBOLS))\n",
    "    \n",
    "    # stopwords removal\n",
    "    if remove_stopwords:\n",
    "        news = \" \".join([word for word in str(news).split() if word not in STOPS])\n",
    "    \n",
    "    if use_stemmer:\n",
    "        news = \" \".join([stemmer.stem(word) for word in news.split()])\n",
    "    return news\n",
    "        \n",
    "        \n",
    "train_df[\"cleaned_article\"] = train_df['article'].apply(lambda news: preprocess(news))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T06:06:25.934130200Z",
     "start_time": "2023-12-05T06:05:40.711377100Z"
    }
   },
   "id": "e173a3f4d8713217"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "id                          0001d1afc246a7964130f43ae940af6bc6c57f01\narticle            By . Associated Press . PUBLISHED: . 14:11 EST...\nhighlights         Bishop John Folda, of North Dakota, is taking ...\ncleaned_article    associated press published 1411 est 25 october...\nName: 0, dtype: object"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T06:06:30.682979500Z",
     "start_time": "2023-12-05T06:06:30.657218400Z"
    }
   },
   "id": "2347a67ada08d1e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Strong Baseline: TF-IDF Summarizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bdf14cc066c2258"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cresc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T06:11:41.574976100Z",
     "start_time": "2023-12-05T06:11:41.114768200Z"
    }
   },
   "id": "b52113aec701de67"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            word = ps.stem(word)\n",
    "            if word in STOPS:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "\n",
    "        frequency_matrix[sent[:15]] = freq_table\n",
    "\n",
    "    return frequency_matrix\n",
    "\n",
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "\n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix\n",
    "\n",
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table\n",
    "\n",
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "\n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix\n",
    "\n",
    "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "\n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "\n",
    "        tf_idf_table = {}\n",
    "\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
    "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "\n",
    "        tf_idf_matrix[sent1] = tf_idf_table\n",
    "\n",
    "    return tf_idf_matrix\n",
    "\n",
    "def _score_sentences(tf_idf_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its word's TF\n",
    "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    sentence_value = {}\n",
    "\n",
    "    for sent, f_table in tf_idf_matrix.items():\n",
    "        total_score_per_sentence = 0\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, score in f_table.items():\n",
    "            total_score_per_sentence += score\n",
    "\n",
    "        sentence_value[sent] = total_score_per_sentence / count_words_in_sentence\n",
    "\n",
    "    return sentence_value\n",
    "\n",
    "def _find_average_score(sentence_value) -> int:\n",
    "    \"\"\"\n",
    "    Find the average score from the sentence value dictionary\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    sum_values = 0\n",
    "    for entry in sentence_value:\n",
    "        sum_values += sentence_value[entry]\n",
    "\n",
    "    # Average value of a sentence from original summary_text\n",
    "    average = (sum_values / len(sentence_value))\n",
    "\n",
    "    return average\n",
    "\n",
    "def _generate_summary(sentences, sentence_value, threshold):\n",
    "    sentence_count = 0\n",
    "    rtv = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:15] in sentence_value and sentence_value[sentence[:15]] >= (threshold):\n",
    "            rtv += \" \" + sentence\n",
    "            sentence_count += 1\n",
    "\n",
    "    return rtv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T06:15:28.017006600Z",
     "start_time": "2023-12-05T06:15:28.006458Z"
    }
   },
   "id": "6c889866d007d138"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(train_df.iloc[0][\"article\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T06:17:04.866873300Z",
     "start_time": "2023-12-05T06:17:04.856847300Z"
    }
   },
   "id": "9ab6aba51ba3d8b4"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "15"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T06:17:18.721423100Z",
     "start_time": "2023-12-05T06:17:18.702378100Z"
    }
   },
   "id": "5886ae3b219d9fb0"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Associated Press . PUBLISHED: . | . UPDATED: .\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(train_df.iloc[0][\"article\"])\n",
    "total_documents = len(sentences)\n",
    "\n",
    "freq_matrix = _create_frequency_matrix(sentences)\n",
    "\n",
    "\n",
    "'''\n",
    "Term frequency (TF) is how often a word appears in a document, divided by how many words are there in a document.\n",
    "'''\n",
    "# 3 Calculate TermFrequency and generate a matrix\n",
    "tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "#print(tf_matrix)\n",
    "\n",
    "# 4 creating table for documents per words\n",
    "count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "#print(count_doc_per_words)\n",
    "\n",
    "'''\n",
    "Inverse document frequency (IDF) is how unique or rare a word is.\n",
    "'''\n",
    "# 5 Calculate IDF and generate a matrix\n",
    "idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "#print(idf_matrix)\n",
    "\n",
    "# 6 Calculate TF-IDF and generate a matrix\n",
    "tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "#print(tf_idf_matrix)\n",
    "\n",
    "# 7 Important Algorithm: score the sentences\n",
    "sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "#print(sentence_scores)\n",
    "\n",
    "# 8 Find the threshold\n",
    "threshold = _find_average_score(sentence_scores)\n",
    "#print(threshold)\n",
    "\n",
    "# 9 Important Algorithm: Generate the summary\n",
    "summary = _generate_summary(sentences, sentence_scores, 1.8 * threshold)\n",
    "print(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T06:17:54.877298500Z",
     "start_time": "2023-12-05T06:17:54.871908500Z"
    }
   },
   "id": "3d7de56defa52125"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7cc1ae6edd101033"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "188cb7bc78c1089"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### References\n",
    "\n",
    "The code is based upon the two sources below:\n",
    "* https://www.kaggle.com/code/elvinagammed/text-summarization-with-bow-tf-idf-and-seq2seq\n",
    "* https://towardsdatascience.com/text-summarization-using-tf-idf-e64a0644ace3 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "604248c167b216ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
